{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>DISCLAIMER !!!</center>                                    \n",
    "\n",
    "1) Вся приведенная здесь информация даётся исключительно в просветительских целях. Пользуйтесь на свой страх и риск.    \n",
    "2) Нет никакой гарантии, что описанный метод и соответствующий софт будут работать с будущими версиями защиты.  \n",
    "3) Всё изложение ведётся примерно в том порядке, в котором я это исследовал. Если у Вас получится лучше, я за Вас рад, но кидаться в меня какашками право же не стоит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этих двух \"живых статьях\" я хочу рассказать об одной интересной задаче, которую мне пришлось решать в ходе моего проекта по исследованию выборов в РФ (в ближайшее время выложу на гитхабе). До того как исследовать какие-то данные, их необходимо ещё получить. На соревнованиях в **[kaggle](https://www.kaggle.com/)** с этим проще. Там данные любезно предоставляются организатором. В реальной жизни увы, всё немножечко сложнее. В частности интересующий меня  **[сайт избиркома](http://izbirkom.ru/region/izbirkom)** не имеет API для доступа к данным. А если бы даже имел, наверняка бы это сделали платной услугой. Поэтому для скачивания данных приходится писать бота и сканировать им весь сайт. Задача не сказать что очень сложная, если бы не одно НО. В РФ почти 100 тысяч УИКов. И каждый УИК требует трёх http-транзакций:  \n",
    "\n",
    "1) Зайти на страничку.     \n",
    "2) Получить данные по результатам голосования.   \n",
    "3) Получить данные по явке в течении дня.    \n",
    "\n",
    "Итого 300 тысяч транзакций. Даже если транзакция занимает в среднем 2 секунды (а для моего интернета это очень хороший, почти невероятный результат), набегает 600 тысяч секунд (и почти всё это время бот просто ждёт завершения очередного http-запроса). Неделя !!!    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение напрашивается само собой. Многопоточная загрузка. Всё верно. Беда однако в том, что **[сайт избиркома](http://izbirkom.ru/region/izbirkom)** позволяет не более двух одновременных http-соединений с одного ip-адреса. Ну будет не неделя, а три с половиной дня. Всё равно слишком долго. Догадливый читатель наверняка сразу вспомнит про прокси-сервера. Опять верно ! Беда в том, что с ними как с погодой в горах. Доподлинно известно какая-то погода всегда есть. Только вот КАКАЯ, никто достоверно не скажет... Так и с прокси. Они всегда есть. Но когда они работают когда нет, насколько тормозят, пускают ли их в определённые подсети и т.п. - не скажет никто. Те которые работают стабильно и предсказуемо - платные.   \n",
    "\n",
    "Есть сервисы, постоянно сканирующие сеть на предмет бесплатных прокси и публикующие их обновляемый список. Можно было бы получать список прокси с них. Увы, как проницательный читатель наверно уже догадался, эта услуга тоже платная. Бесплатно если приспичит, можно зайти на сайт и вбивать оттуда список прокси в своё приложение ручками. Что довольно скучно, а значит мотивирует публику платить владельцам денежки за доступ к API. А чтобы всякие умники не тянули списки с помощью ботов, странички активно противодействуют скраппингу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так собственно и возникла эта задача. Зайти на страничку и вытянуть оттуда защищенную от скраппинга инфу. В качестве \"жертв\" выбраны сервисы **[hidemy.name](https://hidemy.name/en/proxy-list/)** и **[proxyrotator.com](https://www.proxyrotator.com/free-proxy-list/)**.\n",
    "\n",
    "Задача была вполне успешно решена. В результате мой бот получил **неограниченный (!!!)** источник прокси-серверов. Работая в 20-30 потоков(больше потоков уже серьёзно нагружают процессор), и отбирая по ходу работы из многих сотен прокси самые лучшие, он скачивает все данные по выборам за три - три с половиной часа. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Немного о манере изложения</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаюсь, эти статьи я написал недавно, когда захотел этим поделиться. Более того, боевой код написан на java. Для продакшена я вооще предпочитаю что-то статически типизированное. Однако исследовательская часть работы делалась именно так. На питоне, в блокноте jupyter. Именно эту среду я и предпочитаю для разных исследований. Когда можно быстро что-то поменять, что-то посмотреть, нарисовать график, запустить небольшой кусочек кода, тут же изложить свои мысли... Настоящее литературное программирование ! А может быть программирование в стиле мозгового штурма...  \n",
    "Здесь я тоже хотел сохранить дух исследовательской работы, поиска, проб и ошибок. Понимаю что это не совсем честно, ибо писал уже зная результат. Но надеюсь что мне это удалось хотя бы в какой-то мере. Хотел опубликовать это на **[любимом хабре](https://habr.com/ru/top/)**, да побоялся. Больно уж для хабра тема на грани фола, а может и за гранью. Взломов с целью халявы там не любят. Поэтому пусть лежит здесь на гитхабе. Надеюсь найдутся люди, которым это будет интересно и полезно. Хотя бы как небольшой учебник по скраппингу в условиях противодействия оному.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
